<div>
    <h2>Publications [<a href="https://scholar.google.com.hk/citations?user=sQ30WyUAAAAJ&hl=zh-CN">Google Scholar</a>]</h2>
    <table id="tbPublications" width="100%">
        <tr>
            <td width="306">
                <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Perception-Oriented Video Frame Interpolation via Asymmetric Blending</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<i><b>CVPR</b></i>), 2024.</p>
                <p style="color: #333;">
                    Guangyang Wu, <b>Xin Tao</b>, Changlin Li, Wenyi Wang, Xiaohong Liu, Qingqing Zheng
                </p>
                <p><a href="http://www.cse.cuhk.edu.hk/~leojia/papers/mfsr_blur_cvpr15.pdf" style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a><a href="https://arxiv.org/abs/2404.06692" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Feature Decoupling-Recycling Network for Fast Interactive Segmentation</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>ACM International Conference on Multimedia</em> (<i><b>ACM MM</b></i>), 2023.</p>
                <p style="color: #333;">
                    Huimin Zeng, Weinong Wang, <b>Xin Tao</b>, Zhiwei Xiong, Yu-Wing Tai, Wenjie Pei
                </p>
                <p><a href="https://dl.acm.org/doi/abs/10.1145/3581783.3611837" style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a><a href="https://arxiv.org/abs/2308.03529" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Scene-Generalizable Interactive Segmentation of Radiance Fields</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>ACM International Conference on Multimedia</em> (<i><b>ACM MM</b></i>), 2023.</p>
                <p style="color: #333;">
                    Songlin Tang, Wenjie Pei, <b>Xin Tao</b>, Tanghui Jia, Guangming Lu, Yu-Wing Tai
                </p>
                <p><a href="https://dl.acm.org/doi/10.1145/3581783.3612246" style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a><a href="https://arxiv.org/abs/2308.05104" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Compression-Aware Video Super-Resolution</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<i><b>CVPR</b></i>), 2023.</p>
                <p style="color: #333;">
                    Yingwei Wang, Takashi Isobe, Xu Jia, <b>Xin Tao</b>, Huchuan Lu, Yu-Wing Tai
                </p>
                <p><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Compression-Aware_Video_Super-Resolution_CVPR_2023_paper.pdf" style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">DeViT: Deformed Vision Transformers in Video Inpainting</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>ACM International Conference on Multimedia</em> (<i><b>ACM MM</b></i>), 2022.</p>
                <p style="color: #333;">
                    Jiayin Cai, Changlin Li, <b>Xin Tao</b>, Chun Yuan, Yu-Wing Tai
                </p>
                <p><a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548395" style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a><a href="https://arxiv.org/abs/2209.13925" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Look Back and Forth: Video Super-Resolution with Explicit Temporal Difference Modeling</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<i><b>CVPR</b></i>), 2022.</p>
                <p style="color: #333;">
                    Takashi Isobe, Xu Jia, <b>Xin Tao</b>, Changlin Li, Ruihuang Li, Yongjie Shi, Jing Mu, Huchuan Lu, Yu-Wing Tai
                </p>
                <p><a href="https://github.com/junpan19/ETDM" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Project </a><a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Isobe_Look_Back_and_Forth_Video_Super-Resolution_With_Explicit_Temporal_Difference_CVPR_2022_paper.pdf" style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a><a href="https://arxiv.org/abs/2204.07114" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Text-guided Human Image Manipulation via Image-text Shared Space</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> (<i><b>TPAMI</b></i>), 2021.</p>
                <p style="color: #333;">
                    Xiaogang Xu, Ying-Cong Chen, <b>Xin Tao</b>, Jiaya Jia
                </p>
                <p><a href="https://github.com/xiaogang00/Text-Human-Image-Manipulation" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Project </a><a href="https://ieeexplore.ieee.org/document/9444850" style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">MASA-SR: Matching Acceleration and Spatial Adaptation for Reference-Based Image Super-Resolution</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<i><b>CVPR</b></i>), 2021.</p>
                <p style="color: #333;">
                    Liying Lu, Wenbo Li, <b>Xin Tao</b>, Jiangbo Lu, Jiaya Jia
                </p>
                <p><a href="https://github.com/dvlab-research/MASA-SR" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Project </a><a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Lu_MASA-SR_Matching_Acceleration_and_Spatial_Adaptation_for_Reference-Based_Image_Super-Resolution_CVPR_2021_paper.pdf" style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a><a href="https://arxiv.org/abs/2106.02299" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">VCNet: A Robust Approach to Blind Image Inpainting</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>European Conference on Computer Vision</em> (<i><b>ECCV</b></i>), 2020.</p>
                <p style="color: #333;">
                    Yi Wang, Ying-Cong Chen, <b>Xin Tao</b>, Jiaya Jia
                </p>
                <p><a href="https://github.com/shepnerd/blindinpainting_vcnet" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Project </a><a href="https://arxiv.org/abs/2003.06816" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">MuCAN: Multi-Correspondence Aggregation Network for Video Super-Resolution</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>European Conference on Computer Vision</em> (<i><b>ECCV</b></i>), 2020.</p>
                <p style="color: #333;">
                    Wenbo Li, <b>Xin Tao</b>, Taian Guo, Lu Qi, Jiangbo Lu, Jiaya Jia
                </p>
                <p><a href="https://github.com/dvlab-research/Simple-SR" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Project </a><a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123550341.pdf" style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a><a href="https://arxiv.org/abs/2007.11803" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Particularity beyond Commonality: Unpaired Identity Transfer with Multiple References</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>European Conference on Computer Vision</em> (<i><b>ECCV</b></i>), 2020.</p>
                <p style="color: #333;">
                    Ruizheng Wu, <b>Xin Tao</b>, Yingcong Chen, Xiaoyong Shen, Jiaya Jia
                </p>
                <p><a href="https://www.yingcong.me/publication/2020-wu-particularity/" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Project </a><a href="https://jiaya.me/file/papers/idtransfer_eccv20.pdf" style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Wide-context semantic image extrapolation</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<i><b>CVPR</b></i>), 2019.</p>
                <p style="color: #333;">
                    Yi Wang, <b>Xin Tao</b>, Xiaoyong Shen, Jiaya Jia
                </p>
                <p><a href="https://github.com/dvlab-research/outpainting_srn" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Project </a><a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Wide-Context_Semantic_Image_Extrapolation_CVPR_2019_paper.pdf" style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="projects/imgtrans/teaser.png" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Attribute-Driven Spontaneous Motion in Unpaired Image Translation</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE International Conference on Computer Vision</em> (<i><b>ICCV</b></i>), 2019.</p>
                <p style="color: #333;">
                    Ruizheng Wu, <b>Xin Tao</b>, Xiaodong Gu, Xiaoyong Shen, Jiaya Jia
                </p>
                <p><a href="https://jiangsutx.github.io/" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Project </a><a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Wu_Attribute-Driven_Spontaneous_Motion_in_Unpaired_Image_Translation_ICCV_2019_paper.pdf" style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a><a href="https://arxiv.org/abs/1907.01452" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="projects/pssnscdeblur/teaser.png" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Dynamic Scene Deblurring with Parameter Selective Sharing and Nested Skip Connections</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<i><b>CVPR</b></i>), 2019.</p>
                <p style="color: #333;">
                    Hongyun Gao, <b>Xin Tao</b>, Xiaoyong Shen, Jiaya Jia
                </p>
                <p><a href="https://github.com/firenxygao/deblur" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Project </a><a href="https://jiangsutx.github.io/projects/pssnscdeblur/deblur_cvpr19.pdf" style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="projects/srninpaint/teaser.png" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Semantic Regeneration Network</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<i><b>CVPR</b></i>), 2019.</p>
                <p style="color: #333;">
                    Yi Wang, <b>Xin Tao</b>, Xiaoyong Shen, Jiaya Jia
                </p>
                <p><a href="https://github.com/shepnerd/outpainting_srn" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Project </a><a href="https://jiangsutx.github.io/projects/srninpaint/imgextrapolation_cvpr19.pdf" style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="projects/gmcinpaint/teaser.png" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Image Inpainting via Generative Multi-column Convolutional Neural Networks</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>Conference on Neural Information Processing Systems</em> (<i><b>NeuIPS</b></i>), 2018.</p>
                <p style="color: #333;">
                    Yi Wang, <b>Xin Tao</b>, Xiaojuan Qi, Xiaoyong Shen, Jiaya Jia
                </p>
                <p><a href="https://github.com/shepnerd/inpainting_gmcnn" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Project </a><a href="https://arxiv.org/abs/1810.08771" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="projects/srndeblur/teaser.png" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Scale-recurrent Network for Deep Image Deblurring</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<i><b>CVPR</b></i>), 2018.</p>
                <p style="color: #333;">
                    <b>Xin Tao</b>, Hongyun Gao, Xiaoyong Shen, Jue Wang, Jiaya Jia
                </p>
                <p><a href="https://github.com/jiangsutx/SRN-Deblur" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Project </a><a href="https://jiangsutx.github.io/projects/srndeblur/srndeblur_cvpr18.pdf" style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a><a href="https://arxiv.org/abs/1802.01770" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="https://jiangsutx.github.io/projects/facelet/teaser.png" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Facelet-Bank for Fast Portrait Manipulation</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<i><b>CVPR</b></i>), 2018.</p>
                <p style="color: #333;">
                    Ying-Cong Chen, Huaijia Lin, Michelle Shu, Ruiyu Li, <b>Xin Tao</b>, Xiaoyong Shen, Yangang Ye, Jiaya Jia
                </p>
                <p><a href="https://github.com/yingcong/Facelet_Bank" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Project </a><a href="https://arxiv.org/abs/1803.05576" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="projects/defilter/teaser.png" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Zero-order Reverse Filtering</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE International Conference on Computer Vision</em> (<i><b>ICCV</b></i>), 2017.</p>
                <p style="color: #333;">
                    <b>Xin Tao</b>, Chao Zhou, Xiaoyong Shen, Jue Wang, Jiaya Jia
                </p>
                <p><a href="https://github.com/jiangsutx/DeFilter" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Project </a><a href="https://jiangsutx.github.io/projects/defilter/filter_reverse_iccv17.pdf" style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a><a href="https://arxiv.org/abs/1704.04037" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="projects/spmc/teaser.png" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Detail-revealing Deep Video Super-resolution</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE International Conference on Computer Vision</em> (<i><b>ICCV</b></i>),<i><b>Oral,</b></i> 2017.</p>
                <p style="color: #333;">
                    <b>Xin Tao</b>, Hongyun Gao, Renjie Liao, Jue Wang, Jiaya Jia
                </p>
                <p><a href="https://github.com/jiangsutx/SPMC_VideoSR" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Project </a><a href="https://jiangsutx.github.io/projects/spmc/spmc_videosr_iccv17.pdf" style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a><a href="https://arxiv.org/abs/1704.02738" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">High-Quality Correspondence and Segmentation Estimation for Dual-Lens Smart-Phone Portraits</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE International Conference on Computer Vision</em> (<i><b>ICCV</b></i>), 2017.</p>
                <p style="color: #333;">
                    Xiaoyong Shen, Hongyun Gao, <b>Xin Tao</b>, Chao Zhou,Jiaya Jia
                </p>
                <p><a href="https://arxiv.org/abs/1704.02205" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Regional Foremost Matching for Internet Images</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>ACM Transactions on Graphics</em> (<i><b>Proc. SIGGRAPH ASIA</b></i>), 2016.</p>
                <p style="color: #333;">
                    Xiaoyong Shen, <b>Xin Tao</b>, Chao Zhou, Hongyun Gao, Jiaya Jia
                </p>
                <p><a href="http://www.cse.cuhk.edu.hk/leojia/papers/foremost_matching_sa16.pdf" style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Deep Automatic Portrait Matting</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>European Conference on Computer Vision</em> (<i><b>ECCV</b></i>),<i><b>Spotlight,</b></i> 2016.</p>
                <p style="color: #333;">
                    Xiaoyong Shen, <b>Xin Tao</b>, Hongyun Gao, Chao Zhou, Jiaya Jia
                </p>
                <p><a href="http://xiaoyongshen.me/papers/deepmatting.pdf" style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="http://www.cse.cuhk.edu.hk/~leojia/images/depthsingle.jpg" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Break Ames Room Illusion: Depth from General Single Images</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>ACM Transactions on Graphics</em> (<i><b>Proc. SIGGRAPH ASIA</b></i>), 2015.</p>
                <p style="color: #333;">
                    Jianping Shi, <b>Xin Tao</b>, Li Xu, Jiaya Jia
                </p>
                <p><a href="http://www.cse.cuhk.edu.hk/~leojia/projects/sblurdetect/index.html" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Project </a><a href="http://www.cse.cuhk.edu.hk/~leojia/papers/blurestimate_sa15.pdf" style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="http://www.cse.cuhk.edu.hk/~leojia/images/videosuper.jpg" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Video Super-Resolution via Deep Draft-Ensemble Learning</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE International Conference on Computer Vision</em> (<i><b>ICCV</b></i>), 2015.</p>
                <p style="color: #333;">
                    Renjie Liao, <b>Xin Tao</b>, Ruiyu Li, Ziyang Ma, Jiaya Jia
                </p>
                <p><a href="http://www.cse.cuhk.edu.hk/~leojia/projects/DeepSR/index.html" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Project </a><a href="http://www.cse.cuhk.edu.hk/~leojia/papers/videosr_iccv15.pdf" style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="http://www.cse.cuhk.edu.hk/~leojia/images/mfsr.jpg" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Handling Motion Blur in Multi-Frame Super-Resolution</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<i><b>CVPR</b></i>), 2015.</p>
                <p style="color: #333;">
                    Ziyang Ma, Renjie Liao, <b>Xin Tao</b>, Li Xu, Jiaya Jia, Enhua Wu
                </p>
                <p><a href="http://www.cse.cuhk.edu.hk/~leojia/projects/mfsr/index.html" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Project </a><a href="http://www.cse.cuhk.edu.hk/~leojia/papers/mfsr_blur_cvpr15.pdf" style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a></p>
            </td>
        </tr>
        
        <tr>
            <td width="306">
                <img src="http://www.cse.cuhk.edu.hk/~leojia/images/inversekernel.jpg" width="285px" style="box-shadow: 4px 4px 8px #888">
            </td>
            <td>
                <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Inverse Kernels for Fast Spatial Deconvolution</p>
                <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>European Conference on Computer Vision</em> (<i><b>ECCV</b></i>), 2014.</p>
                <p style="color: #333;">
                    Li Xu, <b>Xin Tao</b>, Jiaya Jia
                </p>
                <p><a href="https://example.com/project2" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Project </a><a href="http://www.cse.cuhk.edu.hk/~leojia/papers/inversekernel_eccv14.pdf" style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a></p>
            </td>
        </tr>
        </table>
</div>