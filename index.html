<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({
      google_ad_client: "ca-pub-6848720183547157",
      enable_page_level_ads: true
    });
  </script>
  <link rel="shortcut icon" href="myIcon.ico">
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="keywords"
    content="Xin Tao, Tao Xin, CSE, CUHK, The Chinese University of Hong Kong, Shanghai Jiao Tong University">
  <meta name="description" content="Xin Tao's homepage">
  <link rel="stylesheet" href="javascripts/jemdoc.css" type="text/css" />
  <title>Xin Tao</title>
  <script type="text/javascript">

    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-39824124-1']);
    _gaq.push(['_trackPageview']);

    (function () {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();

  </script>
</head>

<body>

  <div id="layout-content" style="margin-top:25px">

    <table>
      <tbody>
        <tr>
          <td width="670">
            <div id="toptitle">
              <h1>
                <font face="avenir">Xin Tao</font>
                <h1>
            </div>

            <h3>Senior Researcher</h3>
            <p>
              Visual Generation Group, Large Model and Multimedia Technology</br>
              Kuaishou Technology</br>
              Shenzhen, Guangdong, China</br>
              </br>
              Email: <a href="mailto:jiangsutx@gmail.com"> [at] gmail</a>
            </p>
            <p>
              <a href="https://www.linkedin.com/in/xin-tao-33ab555b"><img src="pic/linkedin.png" height="30px"
                  style="margin-bottom:-3px"></a>
              <a href="https://scholar.google.com.hk/citations?user=sQ30WyUAAAAJ&hl=zh-CN"><img
                  src="pic/google_scholar.png" height="30px" style="margin-bottom:-3px"></a>
            </p>
          </td>
          <td>
            <img src="pic/xin_s.jpg" border="0" width="400" style="box-shadow: 4px 4px 8px #888"></br>
          </td>
        </tr>
      </tbody>
    </table>

    <!-- <h2>Biography [<a href="./projects/Mr. Xin_TAO.pdf">CV</a>]</h2> -->
    <h2>Biography</h2>
    <p>
      I am currently a Senior Researcher in Visual Generation Group of Kuaishou Technology, China, since 2020. Before
      that, I was a Senior Researcher in YouTu X-Lab of Tencent, since 2018. I obtained my
      Ph.D. degree in Computer Science and Engineering Department in the Chinese University of Hong Kong (<b>CUHK</b>)
      since 2013. My supervisor is <a href="http://www.cse.cuhk.edu.hk/~leojia/">Prof. Jiaya Jia</a>.
      I received the B. Eng. degree in Information Engineering from Shanghai Jiao Tong University (<b>SJTU</b>) in 2013,
      supervised by <a href="http://qnp.sjtu.edu.cn/content.aspx?info_lb=80&flag=39">Prof. Guangqiang He</a>.
    </p>
    <p>My research interest includes visual restoration and generation. Currently, I am currently serving as a tech lead,
      focusing on the research and development of efficient systems for video generation and editing. <b style="color: #A00000;">We are
        actively seeking talented and self-motivated research interns or full-time researchers to join us</b>. Please feel free to contact us via <a
        href="mailto:taoxin@kuaishou.com">taoxin@kuaishou.com</a>. </p>

    <div>
      <h2>Publications [<a href="https://scholar.google.com.hk/citations?user=sQ30WyUAAAAJ&hl=zh-CN">Google Scholar</a>]
      </h2>
      <table id="tbPublications" width="100%">
        <tr>
          <td width="306">
            <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Perception-Oriented Video
              Frame Interpolation via Asymmetric Blending</p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE Conference on Computer Vision and Pattern
                Recognition</em> (<i><b>CVPR</b></i>), 2024.</p>
            <p style="color: #333;">
              Guangyang Wu, <b>Xin Tao</b>, Changlin Li, Wenyi Wang, Xiaohong Liu, Qingqing Zheng
            </p>
            <p><a href="http://www.cse.cuhk.edu.hk/~leojia/papers/mfsr_blur_cvpr15.pdf"
                style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a><a
                href="https://arxiv.org/abs/2404.06692" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv
              </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Feature Decoupling-Recycling
              Network for Fast Interactive Segmentation</p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>ACM International Conference on Multimedia</em>
              (<i><b>ACM MM</b></i>), 2023.</p>
            <p style="color: #333;">
              Huimin Zeng, Weinong Wang, <b>Xin Tao</b>, Zhiwei Xiong, Yu-Wing Tai, Wenjie Pei
            </p>
            <p><a href="https://dl.acm.org/doi/abs/10.1145/3581783.3611837"
                style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a><a
                href="https://arxiv.org/abs/2308.03529" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv
              </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Scene-Generalizable
              Interactive Segmentation of Radiance Fields</p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>ACM International Conference on Multimedia</em>
              (<i><b>ACM MM</b></i>), 2023.</p>
            <p style="color: #333;">
              Songlin Tang, Wenjie Pei, <b>Xin Tao</b>, Tanghui Jia, Guangming Lu, Yu-Wing Tai
            </p>
            <p><a href="https://dl.acm.org/doi/10.1145/3581783.3612246" style="color: #008CBA; text-decoration: none;"><i
                  class="fas fa-file-pdf"></i> Paper </a><a href="https://arxiv.org/abs/2308.05104"
                style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Compression-Aware Video
              Super-Resolution</p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE Conference on Computer Vision and Pattern
                Recognition</em> (<i><b>CVPR</b></i>), 2023.</p>
            <p style="color: #333;">
              Yingwei Wang, Takashi Isobe, Xu Jia, <b>Xin Tao</b>, Huchuan Lu, Yu-Wing Tai
            </p>
            <p><a
                href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Compression-Aware_Video_Super-Resolution_CVPR_2023_paper.pdf"
                style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">DeViT: Deformed Vision
              Transformers in Video Inpainting</p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>ACM International Conference on Multimedia</em>
              (<i><b>ACM MM</b></i>), 2022.</p>
            <p style="color: #333;">
              Jiayin Cai, Changlin Li, <b>Xin Tao</b>, Chun Yuan, Yu-Wing Tai
            </p>
            <p><a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548395"
                style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a><a
                href="https://arxiv.org/abs/2209.13925" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv
              </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Look Back and Forth: Video
              Super-Resolution with Explicit Temporal Difference Modeling</p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE Conference on Computer Vision and Pattern
                Recognition</em> (<i><b>CVPR</b></i>), 2022.</p>
            <p style="color: #333;">
              Takashi Isobe, Xu Jia, <b>Xin Tao</b>, Changlin Li, Ruihuang Li, Yongjie Shi, Jing Mu, Huchuan Lu, Yu-Wing Tai
            </p>
            <p><a href="https://github.com/junpan19/ETDM" style="color: #008CBA;"><i class="fas fa-project-diagram"></i>
                Project </a><a
                href="https://openaccess.thecvf.com/content/CVPR2022/papers/Isobe_Look_Back_and_Forth_Video_Super-Resolution_With_Explicit_Temporal_Difference_CVPR_2022_paper.pdf"
                style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a><a
                href="https://arxiv.org/abs/2204.07114" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv
              </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Text-guided Human Image
              Manipulation via Image-text Shared Space</p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE Transactions on Pattern Analysis and
                Machine Intelligence</em> (<i><b>TPAMI</b></i>), 2021.</p>
            <p style="color: #333;">
              Xiaogang Xu, Ying-Cong Chen, <b>Xin Tao</b>, Jiaya Jia
            </p>
            <p><a href="https://github.com/xiaogang00/Text-Human-Image-Manipulation" style="color: #008CBA;"><i
                  class="fas fa-project-diagram"></i> Project </a><a href="https://ieeexplore.ieee.org/document/9444850"
                style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">MASA-SR: Matching Acceleration
              and Spatial Adaptation for Reference-Based Image Super-Resolution</p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE Conference on Computer Vision and Pattern
                Recognition</em> (<i><b>CVPR</b></i>), 2021.</p>
            <p style="color: #333;">
              Liying Lu, Wenbo Li, <b>Xin Tao</b>, Jiangbo Lu, Jiaya Jia
            </p>
            <p><a href="https://github.com/dvlab-research/MASA-SR" style="color: #008CBA;"><i
                  class="fas fa-project-diagram"></i> Project </a><a
                href="https://openaccess.thecvf.com/content/CVPR2021/papers/Lu_MASA-SR_Matching_Acceleration_and_Spatial_Adaptation_for_Reference-Based_Image_Super-Resolution_CVPR_2021_paper.pdf"
                style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a><a
                href="https://arxiv.org/abs/2106.02299" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv
              </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">VCNet: A Robust Approach to
              Blind Image Inpainting</p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>European Conference on Computer Vision</em>
              (<i><b>ECCV</b></i>), 2020.</p>
            <p style="color: #333;">
              Yi Wang, Ying-Cong Chen, <b>Xin Tao</b>, Jiaya Jia
            </p>
            <p><a href="https://github.com/shepnerd/blindinpainting_vcnet" style="color: #008CBA;"><i
                  class="fas fa-project-diagram"></i> Project </a><a href="https://arxiv.org/abs/2003.06816"
                style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">MuCAN: Multi-Correspondence
              Aggregation Network for Video Super-Resolution</p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>European Conference on Computer Vision</em>
              (<i><b>ECCV</b></i>), 2020.</p>
            <p style="color: #333;">
              Wenbo Li, <b>Xin Tao</b>, Taian Guo, Lu Qi, Jiangbo Lu, Jiaya Jia
            </p>
            <p><a href="https://github.com/dvlab-research/Simple-SR" style="color: #008CBA;"><i
                  class="fas fa-project-diagram"></i> Project </a><a
                href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123550341.pdf"
                style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a><a
                href="https://arxiv.org/abs/2007.11803" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv
              </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Particularity beyond
              Commonality: Unpaired Identity Transfer with Multiple References</p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>European Conference on Computer Vision</em>
              (<i><b>ECCV</b></i>), 2020.</p>
            <p style="color: #333;">
              Ruizheng Wu, <b>Xin Tao</b>, Yingcong Chen, Xiaoyong Shen, Jiaya Jia
            </p>
            <p><a href="https://www.yingcong.me/publication/2020-wu-particularity/" style="color: #008CBA;"><i
                  class="fas fa-project-diagram"></i> Project </a><a
                href="https://jiaya.me/file/papers/idtransfer_eccv20.pdf" style="color: #008CBA; text-decoration: none;"><i
                  class="fas fa-file-pdf"></i> Paper </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Wide-context semantic image
              extrapolation</p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE Conference on Computer Vision and Pattern
                Recognition</em> (<i><b>CVPR</b></i>), 2019.</p>
            <p style="color: #333;">
              Yi Wang, <b>Xin Tao</b>, Xiaoyong Shen, Jiaya Jia
            </p>
            <p><a href="https://github.com/dvlab-research/outpainting_srn" style="color: #008CBA;"><i
                  class="fas fa-project-diagram"></i> Project </a><a
                href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Wide-Context_Semantic_Image_Extrapolation_CVPR_2019_paper.pdf"
                style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="projects/imgtrans/teaser.png" width="285px" style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Attribute-Driven Spontaneous
              Motion in Unpaired Image Translation</p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE International Conference on Computer
                Vision</em> (<i><b>ICCV</b></i>), 2019.</p>
            <p style="color: #333;">
              Ruizheng Wu, <b>Xin Tao</b>, Xiaodong Gu, Xiaoyong Shen, Jiaya Jia
            </p>
            <p><a href="https://jiangsutx.github.io/" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Project
              </a><a
                href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Wu_Attribute-Driven_Spontaneous_Motion_in_Unpaired_Image_Translation_ICCV_2019_paper.pdf"
                style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a><a
                href="https://arxiv.org/abs/1907.01452" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv
              </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="projects/pssnscdeblur/teaser.png" width="285px" style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Dynamic Scene Deblurring with
              Parameter Selective Sharing and Nested Skip Connections</p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE Conference on Computer Vision and Pattern
                Recognition</em> (<i><b>CVPR</b></i>), 2019.</p>
            <p style="color: #333;">
              Hongyun Gao, <b>Xin Tao</b>, Xiaoyong Shen, Jiaya Jia
            </p>
            <p><a href="https://github.com/firenxygao/deblur" style="color: #008CBA;"><i class="fas fa-project-diagram"></i>
                Project </a><a href="https://jiangsutx.github.io/projects/pssnscdeblur/deblur_cvpr19.pdf"
                style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="projects/srninpaint/teaser.png" width="285px" style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Semantic Regeneration Network
            </p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE Conference on Computer Vision and Pattern
                Recognition</em> (<i><b>CVPR</b></i>), 2019.</p>
            <p style="color: #333;">
              Yi Wang, <b>Xin Tao</b>, Xiaoyong Shen, Jiaya Jia
            </p>
            <p><a href="https://github.com/shepnerd/outpainting_srn" style="color: #008CBA;"><i
                  class="fas fa-project-diagram"></i> Project </a><a
                href="https://jiangsutx.github.io/projects/srninpaint/imgextrapolation_cvpr19.pdf"
                style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="projects/gmcinpaint/teaser.png" width="285px" style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Image Inpainting via
              Generative Multi-column Convolutional Neural Networks</p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>Conference on Neural Information Processing
                Systems</em> (<i><b>NeuIPS</b></i>), 2018.</p>
            <p style="color: #333;">
              Yi Wang, <b>Xin Tao</b>, Xiaojuan Qi, Xiaoyong Shen, Jiaya Jia
            </p>
            <p><a href="https://github.com/shepnerd/inpainting_gmcnn" style="color: #008CBA;"><i
                  class="fas fa-project-diagram"></i> Project </a><a href="https://arxiv.org/abs/1810.08771"
                style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="projects/srndeblur/teaser.png" width="285px" style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Scale-recurrent Network for
              Deep Image Deblurring</p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE Conference on Computer Vision and Pattern
                Recognition</em> (<i><b>CVPR</b></i>), 2018.</p>
            <p style="color: #333;">
              <b>Xin Tao</b>, Hongyun Gao, Xiaoyong Shen, Jue Wang, Jiaya Jia
            </p>
            <p><a href="https://github.com/jiangsutx/SRN-Deblur" style="color: #008CBA;"><i
                  class="fas fa-project-diagram"></i> Project </a><a
                href="https://jiangsutx.github.io/projects/srndeblur/srndeblur_cvpr18.pdf"
                style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a><a
                href="https://arxiv.org/abs/1802.01770" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv
              </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="https://jiangsutx.github.io/projects/facelet/teaser.png" width="285px"
              style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Facelet-Bank for Fast Portrait
              Manipulation</p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE Conference on Computer Vision and Pattern
                Recognition</em> (<i><b>CVPR</b></i>), 2018.</p>
            <p style="color: #333;">
              Ying-Cong Chen, Huaijia Lin, Michelle Shu, Ruiyu Li, <b>Xin Tao</b>, Xiaoyong Shen, Yangang Ye, Jiaya Jia
            </p>
            <p><a href="https://github.com/yingcong/Facelet_Bank" style="color: #008CBA;"><i
                  class="fas fa-project-diagram"></i> Project </a><a href="https://arxiv.org/abs/1803.05576"
                style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="projects/defilter/teaser.png" width="285px" style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Zero-order Reverse Filtering
            </p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE International Conference on Computer
                Vision</em> (<i><b>ICCV</b></i>), 2017.</p>
            <p style="color: #333;">
              <b>Xin Tao</b>, Chao Zhou, Xiaoyong Shen, Jue Wang, Jiaya Jia
            </p>
            <p><a href="https://github.com/jiangsutx/DeFilter" style="color: #008CBA;"><i
                  class="fas fa-project-diagram"></i> Project </a><a
                href="https://jiangsutx.github.io/projects/defilter/filter_reverse_iccv17.pdf"
                style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a><a
                href="https://arxiv.org/abs/1704.04037" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv
              </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="projects/spmc/teaser.png" width="285px" style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Detail-revealing Deep Video
              Super-resolution</p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE International Conference on Computer
                Vision</em> (<i><b>ICCV</b></i>),<i><b>Oral,</b></i> 2017.</p>
            <p style="color: #333;">
              <b>Xin Tao</b>, Hongyun Gao, Renjie Liao, Jue Wang, Jiaya Jia
            </p>
            <p><a href="https://github.com/jiangsutx/SPMC_VideoSR" style="color: #008CBA;"><i
                  class="fas fa-project-diagram"></i> Project </a><a
                href="https://jiangsutx.github.io/projects/spmc/spmc_videosr_iccv17.pdf"
                style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a><a
                href="https://arxiv.org/abs/1704.02738" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Arxiv
              </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">High-Quality Correspondence
              and Segmentation Estimation for Dual-Lens Smart-Phone Portraits</p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE International Conference on Computer
                Vision</em> (<i><b>ICCV</b></i>), 2017.</p>
            <p style="color: #333;">
              Xiaoyong Shen, Hongyun Gao, <b>Xin Tao</b>, Chao Zhou,Jiaya Jia
            </p>
            <p><a href="https://arxiv.org/abs/1704.02205" style="color: #008CBA;"><i class="fas fa-project-diagram"></i>
                Arxiv </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Regional Foremost Matching for
              Internet Images</p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>ACM Transactions on Graphics</em> (<i><b>Proc.
                  SIGGRAPH ASIA</b></i>), 2016.</p>
            <p style="color: #333;">
              Xiaoyong Shen, <b>Xin Tao</b>, Chao Zhou, Hongyun Gao, Jiaya Jia
            </p>
            <p><a href="http://www.cse.cuhk.edu.hk/leojia/papers/foremost_matching_sa16.pdf"
                style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="https://placehold.co/400x285?text=To+Be+Updated" width="285px" style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Deep Automatic Portrait
              Matting</p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>European Conference on Computer Vision</em>
              (<i><b>ECCV</b></i>),<i><b>Spotlight,</b></i> 2016.</p>
            <p style="color: #333;">
              Xiaoyong Shen, <b>Xin Tao</b>, Hongyun Gao, Chao Zhou, Jiaya Jia
            </p>
            <p><a href="http://xiaoyongshen.me/papers/deepmatting.pdf" style="color: #008CBA; text-decoration: none;"><i
                  class="fas fa-file-pdf"></i> Paper </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="http://www.cse.cuhk.edu.hk/~leojia/images/depthsingle.jpg" width="285px"
              style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Break Ames Room Illusion:
              Depth from General Single Images</p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>ACM Transactions on Graphics</em> (<i><b>Proc.
                  SIGGRAPH ASIA</b></i>), 2015.</p>
            <p style="color: #333;">
              Jianping Shi, <b>Xin Tao</b>, Li Xu, Jiaya Jia
            </p>
            <p><a href="http://www.cse.cuhk.edu.hk/~leojia/projects/sblurdetect/index.html" style="color: #008CBA;"><i
                  class="fas fa-project-diagram"></i> Project </a><a
                href="http://www.cse.cuhk.edu.hk/~leojia/papers/blurestimate_sa15.pdf"
                style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="http://www.cse.cuhk.edu.hk/~leojia/images/videosuper.jpg" width="285px"
              style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Video Super-Resolution via
              Deep Draft-Ensemble Learning</p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE International Conference on Computer
                Vision</em> (<i><b>ICCV</b></i>), 2015.</p>
            <p style="color: #333;">
              Renjie Liao, <b>Xin Tao</b>, Ruiyu Li, Ziyang Ma, Jiaya Jia
            </p>
            <p><a href="http://www.cse.cuhk.edu.hk/~leojia/projects/DeepSR/index.html" style="color: #008CBA;"><i
                  class="fas fa-project-diagram"></i> Project </a><a
                href="http://www.cse.cuhk.edu.hk/~leojia/papers/videosr_iccv15.pdf"
                style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="http://www.cse.cuhk.edu.hk/~leojia/images/mfsr.jpg" width="285px"
              style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Handling Motion Blur in
              Multi-Frame Super-Resolution</p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>IEEE Conference on Computer Vision and Pattern
                Recognition</em> (<i><b>CVPR</b></i>), 2015.</p>
            <p style="color: #333;">
              Ziyang Ma, Renjie Liao, <b>Xin Tao</b>, Li Xu, Jiaya Jia, Enhua Wu
            </p>
            <p><a href="http://www.cse.cuhk.edu.hk/~leojia/projects/mfsr/index.html" style="color: #008CBA;"><i
                  class="fas fa-project-diagram"></i> Project </a><a
                href="http://www.cse.cuhk.edu.hk/~leojia/papers/mfsr_blur_cvpr15.pdf"
                style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a></p>
          </td>
        </tr>

        <tr>
          <td width="306">
            <img src="http://www.cse.cuhk.edu.hk/~leojia/images/inversekernel.jpg" width="285px"
              style="box-shadow: 4px 4px 8px #888">
          </td>
          <td>
            <p style="color: #080808; font-size: 20px; font-style: normal; margin-bottom: 0;">Inverse Kernels for Fast
              Spatial Deconvolution</p>
            <p style="font-size: 14px; margin-top: 0; margin-bottom: 1;"><em>European Conference on Computer Vision</em>
              (<i><b>ECCV</b></i>), 2014.</p>
            <p style="color: #333;">
              Li Xu, <b>Xin Tao</b>, Jiaya Jia
            </p>
            <p><a href="https://example.com/project2" style="color: #008CBA;"><i class="fas fa-project-diagram"></i> Project
              </a><a href="http://www.cse.cuhk.edu.hk/~leojia/papers/inversekernel_eccv14.pdf"
                style="color: #008CBA; text-decoration: none;"><i class="fas fa-file-pdf"></i> Paper </a></p>
          </td>
        </tr>
      </table>
    </div>
    <h2>Tech Transfers</h2>
    <table style="border-spacing:2px" width="100%">
      <tr>
        <td>To be updated.</td>
      </tr>
    </table>

    <h2>Education Background</h2>
    <table id="tbEducation" width="100%">
      <tr>
        <td>
          <b>Ph.D.</b> <br>
          <a href="https://www.cse.cuhk.edu.hk/v7/en/index.html">Computer Science and Engineering</a> <br>
          August 2013 - September 2018 | <a href="http://www.cuhk.edu.hk/english/index.html">The Chinese University of
            Hong Kong</a><br>
          <p>&nbsp&nbsp&nbsp Advisor: <a href="http://www.cse.cuhk.edu.hk/~leojia/">Jiaya Jia</a></p>
        </td>
        <td>
          <img src="pic/cuhk.png" width="60px" style="box-shadow: 4px 4px 8px #888">
        </td>
      </tr>
      <tr>
        <td>
          <b>B. Eng.</b> <br>
          <a href="http://english.seiee.sjtu.edu.cn/">Information Engineering</a> | <b>Honored Class (TRC)</b><br>
          January 2011 - January 2013 | <a href="http://en.sjtu.edu.cn/">Shanghai Jiao Tong University</a> <br>
        </td>
        <td>
          <img src="pic/sjtu.png" width="60px" style="box-shadow: 4px 4px 8px #888">
        </td>
      </tr>
    </table>
    <h2>Research Experience</h2>
    <table id="tbResearch" width="100%">
      <tr>
        <td>
          <b>Tech Lead</b> <br>
          <a href="https://ai.kuaishou.com/about">Visual Generation Group</a> | <a href="https://www.kuaishou.com/">Kuaishou</a> <br>
          November 2024 - present | Shenzhen, China <br>
          <a>Mixed Reality Group, Y-tech</a> | <a href="https://www.kuaishou.com/">Kuaishou</a> <br>
          November 2023 - 2024 | Shenzhen, China <br>
          <a>Video Processing and Analysis Group, Video Technology</a> | <a href="https://www.kuaishou.com/">Kuaishou</a> <br>
          November 2020 - 2023 | Shenzhen, China <br>
        </td>
        <td>
          <img src="pic/kuaishou_s.png" width="60px" style="box-shadow: 4px 4px 8px #888">
        </td>
      </tr>
      <tr>
        <td>
          <b>Senior Researcher</b> <br>
          <a href="https://youtu.qq.com/">Youtu Lab</a> | <a href="https://www.tencent.com/">Tencent</a> <br>
          November 2018 - 2020 | Shenzhen, China <br>
        </td>
        <td>
          <img src="pic/youtu.png" width="60px" style="box-shadow: 4px 4px 8px #888">
        </td>
      </tr>
      <tr>
        <td>
          <b>PhD</b> <br>
          <a href="https://www.cse.cuhk.edu.hk/v7/en/index.html">Department of Computer Science and Engineering</a> <br>
          August 2013 - September 2018 | <a href="http://www.cuhk.edu.hk/english/index.html">The Chinese University of
            Hong Kong</a><br>
          <p>&nbsp&nbsp&nbsp Advisor: <a href="http://www.cse.cuhk.edu.hk/~leojia/">Jiaya Jia</a></p>
        </td>
        <td>
          <img src="pic/cuhk.png" width="60px" style="box-shadow: 4px 4px 8px #888">
        </td>
      </tr>
      <tr>
        <td>
          <b>Research Intern</b> <br>
          <a href="https://youtu.qq.com/">Youtu Lab</a> | <a href="https://www.tencent.com/">Tencent</a> <br>
          June 2017 - September 2017 | Shenzhen, China <br>
          <p>&nbsp&nbsp&nbsp Advisor: <a href="https://scholar.google.com/citations?user=nFhLmFkAAAAJ&hl=en">Yu-Wing
              Tai</a></p>
        </td>
        <td>
          <img src="pic/youtu.png" width="60px" style="box-shadow: 4px 4px 8px #888">
        </td>
      </tr>
      <tr>
        <td>
          <b>Research Intern</b> <br>
          <a href="https://research.adobe.com/about-the-labs/ctl/">Creative Technologies Lab</a> | <a
            href="https://research.adobe.com/">Adobe Research</a> <br>
          June 2016 - August 2016 | Greater Seattle Area <br>
          <p>&nbsp&nbsp&nbsp Advisor: <a href="https://juewang725.github.io/">Jue Wang</a></p>
        </td>
        <td>
          <img src="pic/adobe.png" width="60px" style="box-shadow: 4px 4px 8px #888">
        </td>
      </tr>
      <tr>
        <td>
          <b>Research Assistant</b> <br>
          <a href="http://qnp.sjtu.edu.cn/Default.aspx">Laboratory of Quantum Nonlinear Photonics (QNP)</a> <br>
          January 2011 - January 2013 | <a href="http://en.sjtu.edu.cn/">Shanghai Jiao Tong University</a> <br>
          <p>&nbsp&nbsp&nbsp Advisor: <a href="http://qnp.sjtu.edu.cn/content.aspx?info_lb=80&flag=39">Guangqiang He</a>
          </p>
        </td>
        <td>
          <img src="pic/sjtu.png" width="60px" style="box-shadow: 4px 4px 8px #888">
        </td>
      </tr>
    </table>
    <!-- <h2>Honors & Awards</h2>
    <table style="border-spacing:2px" width="100%">
      <tr>
        <td>CUHK Certificate of Merit for Best Teaching Assistant Award</td>
        <td>2014-2015</td>
      </tr>
      <tr>
        <td>CUHK Postgraduate Studentship</td>
        <td>2013-present</td>
      </tr>
      <tr>
        <td>Shanghai outstanding graduates (Top 1%)</td>
        <td>2013</td>
      </tr>
      <tr>
        <td>National Scholarship (Top 1%)</td>
        <td>2011</td>
      </tr>
      <tr>
        <td>SJTU Academic Excellence Scholarship: First-class Prize (Top 1%)</td>
        <td>2011</td>
      </tr>
      <tr>
        <td>Third Prize, China Undergraduate Mathematical Contest in Modeling (CUMCM 2011)</td>
        <td>2011</td>
      </tr>
      <tr>
        <td>Honorable Mention Prize in Mathematical Contest In Modeling 2011 (MCM 2011)</td>
        <td>2011</td>
      </tr>
    </table> -->

    <h2>Professional Activities</h2>
    <table style="border-spacing:2px" width="100%">
      <tr>
        <td>
          <b>Journal Reviewer</b><br>
        </td>
      </tr>
      <tr><td>IEEE Transactions on Pattern Analysis and Machine Intelligence <b>(TPAMI)</b></td></tr>
      <tr><td>Transaction on Graphics <b>(TOG)</b></td></tr>
      <tr><td>International Journal of Computer Vision <b>(IJCV)</b></td></tr>
      <tr><td>Transactions on Image Processing <b>(TIP)</b></td></tr>
      <tr><td>IEEE Transactions on Multimedia</td></tr>
      <tr>
        <td>
          <b>Conference Reviewer</b><br>
        </td>
      </tr>
      <tr>
        <td>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</td>
        <td>2018-2024</td>
      </tr>
      <tr>
        <td>IEEE International Conference on Computer Vision (ICCV)</td>
        <td>2017-2023</td>
      </tr>
      <tr>
        <td>European Conference on Computer Vision (ECCV)</td>
        <td>2018-2024</td>
      </tr>
      <tr>
        <td>International Conference on Machine Learning (ICML)</td>
        <td>2022-2023</td>
      </tr>
      <tr>
        <td>International Conference on Learning Representations (ICLR)</td>
        <td>2021-2023</td>
      </tr>
      <tr>
        <td>Conference on Neural Information Processing Systems (NeurIPS)</td>
        <td>2021-2023</td>
      </tr>
      <tr>
        <td>Asian Conference on Computer Vision (ACCV)</td>
        <td>2018</td>
      </tr>
    </table>

    <h2>Teaching</h2>
    <table id="tbTeaching" border="0" width="100%">
      <tbody>
        <tr>
          <td>CSCI3290 Computational Photography</td>
          <td>2013-2014 / 2014-2015 / 2015-2016 / 2016-2017 Fall</td>
        </tr>
        <tr>
          <td>CSCI1050 Hands-on Introduction to MATLAB</td>
          <td>2013-2014 Spring</td>
        </tr>
        <tr>
          <td>CSCI5280 Image Processing and Computer Vision</td>
          <td>2014-2015 / 2015-2016 Spring</td>
        </tr>
      </tbody>
    </table>
    <!-- 	<h2>Miscellanies</h2> -->

    <!-- <li>
		<h4>Some of My Friends</h4>&nbsp
			<a href="http://appsrv.cse.cuhk.edu.hk/~xuli/">Li Xu</a>,&nbsp
			<a href="http://appsrv.cse.cuhk.edu.hk/~cwlu/">Cewu Lu</a>,&nbsp
			<a href="http://appsrv.cse.cuhk.edu.hk/~qyan/">Qiong Yan</a>,&nbsp
			<a href="http://shijianping.me/">Jianping Shi</a>,&nbsp
			<a href="http://i.cs.hku.hk/~xghan/">Xiaoguang Han</a>,&nbsp
			<a href="http://www.math.zju.edu.cn/ruizhenhu/">Ruizhen Hu</a>,&nbsp
			<a href="http://appsrv.cse.cuhk.edu.hk/~rjliao/">Renjie Liao</a>,&nbsp
			<a href="">Ziyang Ma</a>,&nbsp
			<a href=""http://appsrv.cse.cuhk.edu.hk/~xtao/"">Xin Tao</a>
	        <p style="margin-top:3px">			</p>
	</li> -->
    <!--
	<li>
		<h4>Coding Resources</h4>&nbsp
			<a href="http://opencv.itseez.com/">OpenCV</a>,&nbsp
	        <a href="http://www.cgal.org/">CGAL</a>,&nbsp
	        <a href="http://www.opengl.org/">OpenGL</a>,&nbsp
	        <a href="http://www.nvidia.com/object/cuda_home_new.html">CUDA</a>,&nbsp
	        <a href="http://www.wholetomato.com/">Visual Assist</a>,&nbsp
	        <a href="www.mosek.com/">Mosek</a>,&nbsp
	        <a href="http://www.mathworks.cn/products/matlab/">Matlab</a>,&nbsp
	        <a href="http://software.intel.com/en-us/articles/intel-mkl/">Math Kernel Library</a>,&nbsp
	        <a href="http://www.cs.umd.edu/~mount/ANN/">ANN</a>,&nbsp
	        <a href="http://www.netlib.org/lapack/">LAPACK</a>,&nbsp
	        <a href="http://www.tau.ac.il/~stoledo/taucs/">TAUCS</a>,&nbsp
	        <a href="http://www.codeproject.com/Articles/1300/CxImage">CXimage</a>
	        <p style="margin-top:3px">
			</p>
	</li>
	-->

    <div id="footer">
      <div id="footer-text"></div>
    </div>
    <script>
      (function (i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
          (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date(); a = s.createElement(o),
          m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
      })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

      ga('create', 'UA-85204102-1', 'auto');
      ga('send', 'pageview');
    </script>
    <script src="http://cdn.bootcss.com/canvas-nest.js/1.0.1/canvas-nest.min.js" opacity='0.6' color="0,68,255"
      zIndex="-1"></script>
</body>

</html>